# action-recognition
Using deep learning for action recognition

Used TensorFlow to train and test C3D model on UCF101 dataset of realistic action videos to evaluate whether C3D can be applied to surveillance events detection and where to improve.

Designed a visual interface with PyQt5 to:
- plot real-time learning and validation curves to evaluate models using PyQtGraph;
- display labels, thumbnails and label probabilities in a table.

Screenshots:
terminal during training:
![terminal during training](https://github.com/yy189/action-recognition/raw/master/screenshots/final_accuracy_curves.png)

main interface:
![main interface](https://github.com/yy189/action-recognition/raw/master/screenshots/main_interface.png)

video2datalist interface:
![video2datalist interface](https://github.com/yy189/action-recognition/raw/master/screenshots/video2datalist_interface.png)

real-time accuracy curves:
![real-time accuracy curves](https://github.com/yy189/action-recognition/raw/master/screenshots/real-time_accuracy_curves.png)

final accuracy curves:
![final accuracy curves](https://github.com/yy189/action-recognition/raw/master/screenshots/final_accuracy_curves.png)

likelihood table:
![likelihood table](https://github.com/yy189/action-recognition/raw/master/screenshots/likelihood_table.png)






